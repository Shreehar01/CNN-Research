{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('cirrhosis.CSV')\n",
    "# Note: Importing the same dataset that we used before\n",
    "data_file = r\"./ML Research CNN/tcga.rnaseq_fpkm_uq.example.txt.gz\"\n",
    "data = pd.read_csv(data_file, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project</th>\n",
       "      <th>ENSG00000198886</th>\n",
       "      <th>ENSG00000198938</th>\n",
       "      <th>ENSG00000198712</th>\n",
       "      <th>ENSG00000198804</th>\n",
       "      <th>ENSG00000198695</th>\n",
       "      <th>ENSG00000198899</th>\n",
       "      <th>ENSG00000198763</th>\n",
       "      <th>ENSG00000198727</th>\n",
       "      <th>ENSG00000198840</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000162688</th>\n",
       "      <th>ENSG00000156026</th>\n",
       "      <th>ENSG00000104907</th>\n",
       "      <th>ENSG00000141030</th>\n",
       "      <th>ENSG00000172331</th>\n",
       "      <th>ENSG00000121101</th>\n",
       "      <th>ENSG00000106123</th>\n",
       "      <th>ENSG00000127616</th>\n",
       "      <th>ENSG00000108848</th>\n",
       "      <th>ENSG00000156171</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRCA</td>\n",
       "      <td>142443345</td>\n",
       "      <td>205445265</td>\n",
       "      <td>147699305</td>\n",
       "      <td>117404552</td>\n",
       "      <td>19543789</td>\n",
       "      <td>128074538</td>\n",
       "      <td>100669015</td>\n",
       "      <td>78626906</td>\n",
       "      <td>94521528</td>\n",
       "      <td>...</td>\n",
       "      <td>382567</td>\n",
       "      <td>95352</td>\n",
       "      <td>304543</td>\n",
       "      <td>308747</td>\n",
       "      <td>226017</td>\n",
       "      <td>5440</td>\n",
       "      <td>18911</td>\n",
       "      <td>343402</td>\n",
       "      <td>424057</td>\n",
       "      <td>351094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRCA</td>\n",
       "      <td>78709354</td>\n",
       "      <td>135482824</td>\n",
       "      <td>121180246</td>\n",
       "      <td>88804234</td>\n",
       "      <td>39039866</td>\n",
       "      <td>71029840</td>\n",
       "      <td>41166438</td>\n",
       "      <td>62038429</td>\n",
       "      <td>80445271</td>\n",
       "      <td>...</td>\n",
       "      <td>160738</td>\n",
       "      <td>120179</td>\n",
       "      <td>179252</td>\n",
       "      <td>441331</td>\n",
       "      <td>226645</td>\n",
       "      <td>4703</td>\n",
       "      <td>49153</td>\n",
       "      <td>441665</td>\n",
       "      <td>319501</td>\n",
       "      <td>347807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRCA</td>\n",
       "      <td>99604197</td>\n",
       "      <td>117501309</td>\n",
       "      <td>145945037</td>\n",
       "      <td>125820545</td>\n",
       "      <td>29398067</td>\n",
       "      <td>111459668</td>\n",
       "      <td>57571894</td>\n",
       "      <td>72484994</td>\n",
       "      <td>47528866</td>\n",
       "      <td>...</td>\n",
       "      <td>348926</td>\n",
       "      <td>143608</td>\n",
       "      <td>132642</td>\n",
       "      <td>287426</td>\n",
       "      <td>166473</td>\n",
       "      <td>19628</td>\n",
       "      <td>6255</td>\n",
       "      <td>410590</td>\n",
       "      <td>551479</td>\n",
       "      <td>266470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRCA</td>\n",
       "      <td>199000111</td>\n",
       "      <td>166111590</td>\n",
       "      <td>196725218</td>\n",
       "      <td>172250215</td>\n",
       "      <td>48695291</td>\n",
       "      <td>104508816</td>\n",
       "      <td>102453636</td>\n",
       "      <td>108779676</td>\n",
       "      <td>116175259</td>\n",
       "      <td>...</td>\n",
       "      <td>91047</td>\n",
       "      <td>257669</td>\n",
       "      <td>206994</td>\n",
       "      <td>350421</td>\n",
       "      <td>325966</td>\n",
       "      <td>45224</td>\n",
       "      <td>18814</td>\n",
       "      <td>337762</td>\n",
       "      <td>306825</td>\n",
       "      <td>362499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRCA</td>\n",
       "      <td>101196052</td>\n",
       "      <td>165092542</td>\n",
       "      <td>101739391</td>\n",
       "      <td>98060933</td>\n",
       "      <td>30626957</td>\n",
       "      <td>101645175</td>\n",
       "      <td>61853651</td>\n",
       "      <td>86458871</td>\n",
       "      <td>65193762</td>\n",
       "      <td>...</td>\n",
       "      <td>176419</td>\n",
       "      <td>90094</td>\n",
       "      <td>130460</td>\n",
       "      <td>415061</td>\n",
       "      <td>176510</td>\n",
       "      <td>16120</td>\n",
       "      <td>28053</td>\n",
       "      <td>241460</td>\n",
       "      <td>269349</td>\n",
       "      <td>277226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  project  ENSG00000198886  ENSG00000198938  ENSG00000198712  ENSG00000198804  \\\n",
       "0    BRCA        142443345        205445265        147699305        117404552   \n",
       "1    BRCA         78709354        135482824        121180246         88804234   \n",
       "2    BRCA         99604197        117501309        145945037        125820545   \n",
       "3    BRCA        199000111        166111590        196725218        172250215   \n",
       "4    BRCA        101196052        165092542        101739391         98060933   \n",
       "\n",
       "   ENSG00000198695  ENSG00000198899  ENSG00000198763  ENSG00000198727  \\\n",
       "0         19543789        128074538        100669015         78626906   \n",
       "1         39039866         71029840         41166438         62038429   \n",
       "2         29398067        111459668         57571894         72484994   \n",
       "3         48695291        104508816        102453636        108779676   \n",
       "4         30626957        101645175         61853651         86458871   \n",
       "\n",
       "   ENSG00000198840  ...  ENSG00000162688  ENSG00000156026  ENSG00000104907  \\\n",
       "0         94521528  ...           382567            95352           304543   \n",
       "1         80445271  ...           160738           120179           179252   \n",
       "2         47528866  ...           348926           143608           132642   \n",
       "3        116175259  ...            91047           257669           206994   \n",
       "4         65193762  ...           176419            90094           130460   \n",
       "\n",
       "   ENSG00000141030  ENSG00000172331  ENSG00000121101  ENSG00000106123  \\\n",
       "0           308747           226017             5440            18911   \n",
       "1           441331           226645             4703            49153   \n",
       "2           287426           166473            19628             6255   \n",
       "3           350421           325966            45224            18814   \n",
       "4           415061           176510            16120            28053   \n",
       "\n",
       "   ENSG00000127616  ENSG00000108848  ENSG00000156171  \n",
       "0           343402           424057           351094  \n",
       "1           441665           319501           347807  \n",
       "2           410590           551479           266470  \n",
       "3           337762           306825           362499  \n",
       "4           241460           269349           277226  \n",
       "\n",
       "[5 rows x 5001 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: 5000 columns. Need to use PCA later on. \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 5001)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BRCA', 'COAD', 'KIRC'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 output variables\n",
    "data['project'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Standardizing so that we can use PCA\n",
    "df = data.loc[:, data.columns != 'project']\n",
    "from sklearn import preprocessing\n",
    "names = df.columns\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaled_df = scaler.fit_transform(df)\n",
    "scaled_df = pd.DataFrame(scaled_df, columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>590</th>\n",
       "      <th>591</th>\n",
       "      <th>592</th>\n",
       "      <th>593</th>\n",
       "      <th>594</th>\n",
       "      <th>595</th>\n",
       "      <th>596</th>\n",
       "      <th>597</th>\n",
       "      <th>598</th>\n",
       "      <th>599</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.839657</td>\n",
       "      <td>-10.445880</td>\n",
       "      <td>15.237815</td>\n",
       "      <td>-16.702372</td>\n",
       "      <td>8.842484</td>\n",
       "      <td>3.373958</td>\n",
       "      <td>-1.665245</td>\n",
       "      <td>1.554028</td>\n",
       "      <td>7.223032</td>\n",
       "      <td>6.370468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101700</td>\n",
       "      <td>0.039865</td>\n",
       "      <td>0.021387</td>\n",
       "      <td>0.036883</td>\n",
       "      <td>0.027455</td>\n",
       "      <td>-0.043504</td>\n",
       "      <td>0.021644</td>\n",
       "      <td>-0.008426</td>\n",
       "      <td>-0.096327</td>\n",
       "      <td>2.944455e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.418740</td>\n",
       "      <td>-18.714515</td>\n",
       "      <td>18.695366</td>\n",
       "      <td>3.499248</td>\n",
       "      <td>-11.228010</td>\n",
       "      <td>-0.568816</td>\n",
       "      <td>6.193201</td>\n",
       "      <td>2.626075</td>\n",
       "      <td>-11.549008</td>\n",
       "      <td>1.337317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003278</td>\n",
       "      <td>0.100219</td>\n",
       "      <td>0.037245</td>\n",
       "      <td>-0.004829</td>\n",
       "      <td>-0.072288</td>\n",
       "      <td>0.055188</td>\n",
       "      <td>-0.016110</td>\n",
       "      <td>0.023687</td>\n",
       "      <td>-0.034666</td>\n",
       "      <td>2.944455e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.507426</td>\n",
       "      <td>-28.774181</td>\n",
       "      <td>14.346849</td>\n",
       "      <td>-6.032672</td>\n",
       "      <td>-1.665448</td>\n",
       "      <td>-2.608347</td>\n",
       "      <td>2.873119</td>\n",
       "      <td>-3.018353</td>\n",
       "      <td>-3.001003</td>\n",
       "      <td>0.967144</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013474</td>\n",
       "      <td>0.095272</td>\n",
       "      <td>0.091443</td>\n",
       "      <td>0.006505</td>\n",
       "      <td>0.080337</td>\n",
       "      <td>-0.045930</td>\n",
       "      <td>0.037766</td>\n",
       "      <td>-0.008267</td>\n",
       "      <td>0.012735</td>\n",
       "      <td>2.944455e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6.635627</td>\n",
       "      <td>-13.545971</td>\n",
       "      <td>16.128075</td>\n",
       "      <td>-16.766871</td>\n",
       "      <td>-8.800637</td>\n",
       "      <td>23.237971</td>\n",
       "      <td>-0.205306</td>\n",
       "      <td>-7.339374</td>\n",
       "      <td>-1.599968</td>\n",
       "      <td>1.460868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046064</td>\n",
       "      <td>0.104461</td>\n",
       "      <td>-0.066532</td>\n",
       "      <td>-0.084757</td>\n",
       "      <td>-0.019888</td>\n",
       "      <td>0.057780</td>\n",
       "      <td>-0.052449</td>\n",
       "      <td>0.011639</td>\n",
       "      <td>0.074563</td>\n",
       "      <td>2.944455e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-20.454584</td>\n",
       "      <td>-26.694659</td>\n",
       "      <td>8.042968</td>\n",
       "      <td>3.883628</td>\n",
       "      <td>5.067656</td>\n",
       "      <td>7.025973</td>\n",
       "      <td>-2.605806</td>\n",
       "      <td>2.030753</td>\n",
       "      <td>4.197511</td>\n",
       "      <td>4.008807</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076781</td>\n",
       "      <td>0.089052</td>\n",
       "      <td>-0.021307</td>\n",
       "      <td>0.191474</td>\n",
       "      <td>-0.197166</td>\n",
       "      <td>0.060877</td>\n",
       "      <td>0.045007</td>\n",
       "      <td>-0.032184</td>\n",
       "      <td>0.077287</td>\n",
       "      <td>2.944455e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>-26.348827</td>\n",
       "      <td>27.139345</td>\n",
       "      <td>-3.913466</td>\n",
       "      <td>-1.927165</td>\n",
       "      <td>-7.841317</td>\n",
       "      <td>-8.896410</td>\n",
       "      <td>6.165722</td>\n",
       "      <td>-6.550848</td>\n",
       "      <td>-3.841771</td>\n",
       "      <td>-2.034988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220170</td>\n",
       "      <td>-0.138107</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>-0.125084</td>\n",
       "      <td>0.016085</td>\n",
       "      <td>-0.072357</td>\n",
       "      <td>0.084657</td>\n",
       "      <td>0.118905</td>\n",
       "      <td>-0.081201</td>\n",
       "      <td>2.944455e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>-32.943383</td>\n",
       "      <td>13.944946</td>\n",
       "      <td>-9.666437</td>\n",
       "      <td>-5.316212</td>\n",
       "      <td>-5.963663</td>\n",
       "      <td>1.328434</td>\n",
       "      <td>-3.631446</td>\n",
       "      <td>-5.033466</td>\n",
       "      <td>9.674514</td>\n",
       "      <td>0.461627</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.185786</td>\n",
       "      <td>-0.388123</td>\n",
       "      <td>0.257948</td>\n",
       "      <td>0.351359</td>\n",
       "      <td>-0.102648</td>\n",
       "      <td>0.015429</td>\n",
       "      <td>0.201576</td>\n",
       "      <td>0.161453</td>\n",
       "      <td>-0.077303</td>\n",
       "      <td>2.944455e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>-36.881629</td>\n",
       "      <td>12.909506</td>\n",
       "      <td>0.796766</td>\n",
       "      <td>17.039347</td>\n",
       "      <td>-13.931855</td>\n",
       "      <td>1.611128</td>\n",
       "      <td>3.877636</td>\n",
       "      <td>0.752845</td>\n",
       "      <td>1.587419</td>\n",
       "      <td>14.086768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040499</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>-0.023970</td>\n",
       "      <td>0.051491</td>\n",
       "      <td>0.014701</td>\n",
       "      <td>0.190600</td>\n",
       "      <td>-0.050214</td>\n",
       "      <td>0.061451</td>\n",
       "      <td>0.205603</td>\n",
       "      <td>2.944455e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>-16.995201</td>\n",
       "      <td>33.833190</td>\n",
       "      <td>-2.559493</td>\n",
       "      <td>-16.987569</td>\n",
       "      <td>1.239054</td>\n",
       "      <td>-13.875813</td>\n",
       "      <td>-5.992537</td>\n",
       "      <td>2.454351</td>\n",
       "      <td>6.277324</td>\n",
       "      <td>-0.119567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175142</td>\n",
       "      <td>-0.057578</td>\n",
       "      <td>-0.105122</td>\n",
       "      <td>-0.184133</td>\n",
       "      <td>-0.081636</td>\n",
       "      <td>-0.041033</td>\n",
       "      <td>-0.076382</td>\n",
       "      <td>-0.135030</td>\n",
       "      <td>0.065253</td>\n",
       "      <td>2.944455e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>-24.371265</td>\n",
       "      <td>36.982857</td>\n",
       "      <td>1.164833</td>\n",
       "      <td>3.377671</td>\n",
       "      <td>2.418476</td>\n",
       "      <td>-19.386115</td>\n",
       "      <td>4.517503</td>\n",
       "      <td>4.541036</td>\n",
       "      <td>-14.598682</td>\n",
       "      <td>-0.345476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024920</td>\n",
       "      <td>0.012625</td>\n",
       "      <td>0.098340</td>\n",
       "      <td>0.357264</td>\n",
       "      <td>-0.203247</td>\n",
       "      <td>-0.123773</td>\n",
       "      <td>0.096811</td>\n",
       "      <td>0.178964</td>\n",
       "      <td>-0.207705</td>\n",
       "      <td>2.944455e-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 600 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4          5    \\\n",
       "0    -2.839657 -10.445880  15.237815 -16.702372   8.842484   3.373958   \n",
       "1    12.418740 -18.714515  18.695366   3.499248 -11.228010  -0.568816   \n",
       "2     0.507426 -28.774181  14.346849  -6.032672  -1.665448  -2.608347   \n",
       "3    -6.635627 -13.545971  16.128075 -16.766871  -8.800637  23.237971   \n",
       "4   -20.454584 -26.694659   8.042968   3.883628   5.067656   7.025973   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "595 -26.348827  27.139345  -3.913466  -1.927165  -7.841317  -8.896410   \n",
       "596 -32.943383  13.944946  -9.666437  -5.316212  -5.963663   1.328434   \n",
       "597 -36.881629  12.909506   0.796766  17.039347 -13.931855   1.611128   \n",
       "598 -16.995201  33.833190  -2.559493 -16.987569   1.239054 -13.875813   \n",
       "599 -24.371265  36.982857   1.164833   3.377671   2.418476 -19.386115   \n",
       "\n",
       "          6         7          8          9    ...       590       591  \\\n",
       "0   -1.665245  1.554028   7.223032   6.370468  ...  0.101700  0.039865   \n",
       "1    6.193201  2.626075 -11.549008   1.337317  ...  0.003278  0.100219   \n",
       "2    2.873119 -3.018353  -3.001003   0.967144  ... -0.013474  0.095272   \n",
       "3   -0.205306 -7.339374  -1.599968   1.460868  ...  0.046064  0.104461   \n",
       "4   -2.605806  2.030753   4.197511   4.008807  ... -0.076781  0.089052   \n",
       "..        ...       ...        ...        ...  ...       ...       ...   \n",
       "595  6.165722 -6.550848  -3.841771  -2.034988  ...  0.220170 -0.138107   \n",
       "596 -3.631446 -5.033466   9.674514   0.461627  ... -0.185786 -0.388123   \n",
       "597  3.877636  0.752845   1.587419  14.086768  ...  0.040499  0.004179   \n",
       "598 -5.992537  2.454351   6.277324  -0.119567  ...  0.175142 -0.057578   \n",
       "599  4.517503  4.541036 -14.598682  -0.345476  ...  0.024920  0.012625   \n",
       "\n",
       "          592       593       594       595       596       597       598  \\\n",
       "0    0.021387  0.036883  0.027455 -0.043504  0.021644 -0.008426 -0.096327   \n",
       "1    0.037245 -0.004829 -0.072288  0.055188 -0.016110  0.023687 -0.034666   \n",
       "2    0.091443  0.006505  0.080337 -0.045930  0.037766 -0.008267  0.012735   \n",
       "3   -0.066532 -0.084757 -0.019888  0.057780 -0.052449  0.011639  0.074563   \n",
       "4   -0.021307  0.191474 -0.197166  0.060877  0.045007 -0.032184  0.077287   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "595  0.001747 -0.125084  0.016085 -0.072357  0.084657  0.118905 -0.081201   \n",
       "596  0.257948  0.351359 -0.102648  0.015429  0.201576  0.161453 -0.077303   \n",
       "597 -0.023970  0.051491  0.014701  0.190600 -0.050214  0.061451  0.205603   \n",
       "598 -0.105122 -0.184133 -0.081636 -0.041033 -0.076382 -0.135030  0.065253   \n",
       "599  0.098340  0.357264 -0.203247 -0.123773  0.096811  0.178964 -0.207705   \n",
       "\n",
       "              599  \n",
       "0    2.944455e-15  \n",
       "1    2.944455e-15  \n",
       "2    2.944455e-15  \n",
       "3    2.944455e-15  \n",
       "4    2.944455e-15  \n",
       "..            ...  \n",
       "595  2.944455e-15  \n",
       "596  2.944455e-15  \n",
       "597  2.944455e-15  \n",
       "598  2.944455e-15  \n",
       "599  2.944455e-15  \n",
       "\n",
       "[600 rows x 600 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: Using the PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition\n",
    "\n",
    "pca = decomposition.PCA()\n",
    "df_plot = pd.DataFrame(pca.fit_transform(scaled_df), index=data.index)\n",
    "df_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA()\n",
    "# fit : Run PCA\n",
    "df_PC = pca.fit(scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.plot(df_PC.explained_variance_ratio_, '-o', label='Individual component')\n",
    "plt.plot(np.cumsum(df_PC.explained_variance_ratio_), 'bo-', label='cumulative PVE')\n",
    "\n",
    "plt.ylabel('percentage of variance explained')\n",
    "plt.xlabel('Principal components')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15293673 0.24174977 0.30315427 0.355137   0.3882034  0.41360936\n",
      " 0.43321753 0.45155085 0.46880016 0.48396303 0.49840139 0.51084905\n",
      " 0.5220417  0.53278277 0.54298662 0.55261814 0.56118531 0.56921006\n",
      " 0.57698085 0.58405942 0.59069431 0.59714626 0.60321559 0.60891179\n",
      " 0.61449137 0.61995392 0.62520628 0.6301012  0.6348273  0.63945158\n",
      " 0.64377963 0.64803345 0.65211666 0.65607026 0.65982107 0.6635507\n",
      " 0.66722632 0.67087303 0.67441573 0.67789729 0.68129983 0.68460993\n",
      " 0.68781765 0.69093938 0.69397969 0.69696957 0.69991297 0.7028317\n",
      " 0.70574137 0.70855415 0.71134047 0.71407134 0.7167468  0.71938739\n",
      " 0.7219941  0.72451644 0.72702223 0.72945552 0.73186405 0.73424084\n",
      " 0.73658973 0.7388832  0.74117136 0.74342685 0.74564599 0.74784472\n",
      " 0.75003146 0.75215318 0.75425067 0.75634    0.75840425 0.76043711\n",
      " 0.76243366 0.76440704 0.76636196 0.76825509 0.77013911 0.77199741\n",
      " 0.773823   0.77563231 0.77743288 0.77920183 0.78096388 0.78270763\n",
      " 0.78442747 0.78611692 0.78779648 0.78945527 0.7910971  0.79271146\n",
      " 0.79431057 0.79589797 0.79744625 0.79898606 0.80051603 0.80202884\n",
      " 0.80351659 0.80498556 0.8064381  0.80787888 0.80931186 0.81073431\n",
      " 0.81214034 0.81353581 0.81491625 0.81628529 0.81763957 0.81898896\n",
      " 0.82032177 0.82164416 0.82293971 0.82422001 0.8254926  0.82675318\n",
      " 0.82800895 0.82925562 0.83049427 0.83172117 0.83293908 0.83414896\n",
      " 0.83533499 0.83651602 0.83769488 0.83884013 0.83997748 0.84110609\n",
      " 0.8422278  0.84333532 0.84443945 0.8455314  0.84661445 0.84769536\n",
      " 0.8487647  0.84982137 0.85087093 0.85191652 0.85295036 0.85397784\n",
      " 0.85499459 0.8560067  0.85700944 0.85800898 0.85900154 0.85997745\n",
      " 0.86094773 0.86191326 0.86286839 0.86381934 0.86476405 0.86569793\n",
      " 0.86662945 0.86755534 0.8684727  0.86937514 0.87027089 0.87115972\n",
      " 0.87204514 0.87292705 0.8738055  0.87467628 0.87554209 0.87639801\n",
      " 0.87723981 0.87807711 0.87890902 0.87973895 0.88056191 0.88138047\n",
      " 0.88219487 0.88300435 0.88380681 0.88460621 0.88540162 0.88618855\n",
      " 0.88697112 0.88774877 0.888518   0.88928297 0.89004226 0.89079857\n",
      " 0.89154565 0.89228753 0.89302711 0.89376354 0.89449508 0.89522156\n",
      " 0.89594204 0.89666016 0.89737155 0.89807603 0.8987764  0.89947274\n",
      " 0.90016557 0.90085433 0.90153826 0.90221743 0.90289051 0.90356087\n",
      " 0.90422681 0.90489204 0.90555029 0.90620293 0.90685134 0.90749742\n",
      " 0.90813584 0.90876986 0.90940203 0.91003076 0.91065457 0.91127477\n",
      " 0.91188706 0.91249843 0.91310671 0.91371019 0.91431158 0.91490697\n",
      " 0.91549901 0.91608519 0.91666865 0.91725194 0.91783053 0.91840819\n",
      " 0.91897828 0.91954613 0.92011019 0.92067142 0.92123033 0.92178359\n",
      " 0.92233657 0.92288298 0.92342802 0.92396963 0.92450725 0.92503729\n",
      " 0.92556522 0.92608443 0.92660097 0.92711661 0.92762825 0.92813626\n",
      " 0.92864264 0.92914491 0.92964435 0.93014255 0.93063887 0.93112913\n",
      " 0.93161687 0.93209898 0.93257893 0.93305659 0.93353347 0.93400728\n",
      " 0.93447935 0.93494892 0.93541656 0.93587943 0.93634043 0.9367927\n",
      " 0.93724476 0.93769113 0.93813608 0.93858016 0.93902182 0.93945998\n",
      " 0.93989556 0.94032876 0.94075977 0.9411892  0.94161725 0.94204032\n",
      " 0.94246248 0.94288034 0.94329679 0.94371237 0.94412099 0.94452928\n",
      " 0.94493405 0.9453372  0.94573703 0.94613221 0.94652615 0.94691778\n",
      " 0.94730851 0.94769638 0.94808166 0.94846637 0.9488481  0.94922663\n",
      " 0.94960209 0.9499758  0.95034612 0.95071398 0.95107972 0.95144429\n",
      " 0.95180711 0.95216778 0.95252564 0.9528809  0.95323427 0.9535825\n",
      " 0.95392976 0.95427455 0.95461907 0.95495986 0.95529837 0.9556356\n",
      " 0.95597041 0.9563036  0.95663478 0.95696515 0.95729197 0.95761672\n",
      " 0.9579398  0.95826139 0.95857907 0.95889654 0.95921259 0.95952619\n",
      " 0.95983853 0.96014725 0.96045408 0.96076022 0.96106381 0.96136612\n",
      " 0.96166526 0.96196108 0.962256   0.96254873 0.96284048 0.96313129\n",
      " 0.96341913 0.96370454 0.96398951 0.96427231 0.96455064 0.96482854\n",
      " 0.96510489 0.96538032 0.96565345 0.96592506 0.9661945  0.96646358\n",
      " 0.96673003 0.96699388 0.96725702 0.96751861 0.96777962 0.96803824\n",
      " 0.96829606 0.96855201 0.96880622 0.96906015 0.96931168 0.96955985\n",
      " 0.969807   0.97005151 0.9702946  0.97053682 0.97077809 0.97101783\n",
      " 0.97125598 0.97149314 0.97172728 0.97196112 0.97219407 0.97242573\n",
      " 0.97265533 0.97288314 0.97310965 0.97333423 0.9735577  0.97377823\n",
      " 0.97399822 0.97421666 0.97443321 0.97464926 0.97486482 0.97507933\n",
      " 0.97529349 0.97550561 0.97571565 0.97592475 0.97613344 0.97634095\n",
      " 0.97654694 0.97675151 0.97695521 0.97715784 0.97735988 0.97755943\n",
      " 0.97775822 0.97795651 0.97815348 0.97834846 0.97854259 0.97873533\n",
      " 0.97892612 0.97911538 0.97930405 0.97949221 0.97967891 0.97986428\n",
      " 0.98004836 0.98023122 0.98041374 0.9805948  0.98077513 0.98095519\n",
      " 0.98113357 0.98131114 0.98148782 0.98166308 0.98183671 0.98200958\n",
      " 0.98218183 0.98235274 0.98252155 0.98268994 0.98285763 0.98302411\n",
      " 0.98318934 0.983353   0.98351592 0.98367832 0.98383961 0.98400001\n",
      " 0.98415966 0.98431704 0.98447423 0.98463011 0.98478565 0.98494009\n",
      " 0.98509372 0.98524596 0.98539752 0.985548   0.98569645 0.98584406\n",
      " 0.98599088 0.98613729 0.9862832  0.98642812 0.98657125 0.98671387\n",
      " 0.98685592 0.98699691 0.98713684 0.98727585 0.9874139  0.98755144\n",
      " 0.98768853 0.98782428 0.98795975 0.98809504 0.98822794 0.98836045\n",
      " 0.98849212 0.98862348 0.98875364 0.98888271 0.98901131 0.98913903\n",
      " 0.98926629 0.9893927  0.98951791 0.989642   0.9897649  0.98988747\n",
      " 0.99000873 0.99012921 0.99024873 0.99036779 0.99048582 0.99060368\n",
      " 0.99072088 0.9908372  0.99095296 0.99106759 0.99118058 0.99129333\n",
      " 0.99140559 0.99151715 0.9916281  0.99173843 0.9918475  0.99195581\n",
      " 0.99206365 0.99217106 0.99227759 0.99238336 0.99248827 0.99259253\n",
      " 0.99269658 0.99279961 0.99290216 0.99300386 0.99310412 0.99320387\n",
      " 0.99330328 0.9934019  0.99349975 0.99359718 0.99369345 0.9937894\n",
      " 0.99388445 0.99397895 0.99407287 0.99416645 0.99425924 0.99435135\n",
      " 0.99444263 0.9945335  0.99462375 0.99471338 0.99480248 0.99489065\n",
      " 0.99497792 0.99506507 0.99515187 0.99523818 0.99532379 0.99540797\n",
      " 0.9954915  0.99557428 0.99565656 0.99573817 0.99581954 0.9959\n",
      " 0.99597983 0.99605907 0.99613815 0.9962168  0.99629459 0.99637169\n",
      " 0.99644815 0.99652356 0.99659859 0.99667245 0.99674587 0.99681825\n",
      " 0.99689006 0.99696167 0.99703265 0.99710322 0.99717358 0.99724275\n",
      " 0.99731155 0.99738028 0.99744785 0.99751498 0.99758171 0.99764737\n",
      " 0.99771258 0.99777757 0.9978422  0.99790586 0.99796845 0.99803065\n",
      " 0.99809256 0.99815335 0.99821368 0.9982735  0.99833306 0.99839152\n",
      " 0.99844958 0.99850739 0.99856478 0.9986209  0.99867643 0.99873164\n",
      " 0.99878537 0.99883867 0.99889175 0.99894426 0.99899592 0.9990474\n",
      " 0.99909826 0.99914888 0.99919908 0.99924799 0.99929654 0.99934445\n",
      " 0.99939147 0.99943716 0.9994825  0.99952654 0.99956969 0.99961237\n",
      " 0.99965415 0.9996956  0.99973662 0.99977579 0.99981358 0.99984963\n",
      " 0.99988355 0.99991583 0.99994525 0.99997367 1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "# We select 25 features because they add upto 60% of the variance\n",
    "print(np.cumsum(df_PC.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the 7*7 convolutional matrix from the 25 principal components\n",
    "def create_one_row(row):\n",
    "    list_temp = []\n",
    "    for value in row:\n",
    "        list_temp.append(value - row.mean())\n",
    "    list_row = np.array(list_temp).reshape(7, 7)\n",
    "    return list_row\n",
    "\n",
    "def transform_dataframe(df):\n",
    "    final_df = []\n",
    "    for i in range(len(df)):\n",
    "        final_df.append(create_one_row(df.iloc[i].values))\n",
    "    return final_df\n",
    "\n",
    "X = pd.DataFrame()\n",
    "for i in range(49):\n",
    "    X[i] = df_plot[i]\n",
    "final_df = transform_dataframe(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -2.91760034, -10.52382301,  15.15987133, -16.78031545,\n",
       "          8.76454104,   3.29601439,  -1.74318856],\n",
       "       [  1.47608451,   7.14508857,   6.29252492,  -8.59814142,\n",
       "          0.68937842,   4.05889839,   1.14134181],\n",
       "       [  5.31413015,  -4.56060198,   9.47647651,   2.73144207,\n",
       "         -6.46875832,   2.78711941,   3.72190592],\n",
       "       [ -2.46040524,  -3.56222878,   3.06622712,  -0.52936116,\n",
       "         -2.25796719, -10.72882395,  -1.61242208],\n",
       "       [  4.81521559,  -1.28946043,  -0.65546513,  -2.27426662,\n",
       "          7.25990473,   1.3344682 ,  -0.81261106],\n",
       "       [ -4.14580086,   5.63157891,  -4.79395033,  -1.04329838,\n",
       "          0.87550798,  -4.58126743,  -1.14935823],\n",
       "       [  4.15125045,  -5.29048756,  -0.15460514,  -1.87306942,\n",
       "          4.21976918,   1.87758601,  -4.47904753]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: Looking at how a convolutional matrix looks like\n",
    "trial = final_df[0]\n",
    "trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Importing the base image\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "img = Image.open('rose.jpg').convert('RGBA')\n",
    "arr = np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\user\\anaconda3\\lib\\site-packages (4.5.5.62)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from opencv-python) (1.20.3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the base image into matrix in black and white form\n",
    "!pip3 install opencv-python\n",
    "import cv2\n",
    "image = cv2.imread(\"rose.jpg\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import rescale_intensity\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "        \n",
    "# Note: Convolving with each of the 600 7*7 convolutional matrix     \n",
    "final_output = []\n",
    "for i in range(len(final_df)):\n",
    "    convolveOutput = cv2.filter2D(gray, -1, final_df[i])\n",
    "    final_output.append(convolveOutput)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Storing the convolved base image in different folders based on the output\n",
    "sharp_kernel = np.array([[0, -1, 0],\n",
    "                    [-1, 5, -1],\n",
    "                    [0, -1, 0]])\n",
    "counter = 0\n",
    "for index in range(len(final_df)):\n",
    "    name = 'img' + str(counter) + '.png'\n",
    "    path = './data/train3/'\n",
    "    if data.project.values[index] == \"BRCA\":\n",
    "        path = path + \"BRCA/\"\n",
    "        pathname = path + name\n",
    "        cv2.imwrite(pathname, final_output[index])\n",
    "        img = cv2.imread(pathname)\n",
    "        flt_img = cv2.filter2D(src=img, ddepth=-1, kernel=sharp_kernel)\n",
    "        cv2.imwrite(pathname, flt_img)\n",
    "    elif data.project.values[index] == \"COAD\":\n",
    "        path = path + \"COAD/\"\n",
    "        pathname = path + name\n",
    "        cv2.imwrite(pathname, final_output[index])\n",
    "        img = cv2.imread(pathname)\n",
    "        flt_img = cv2.filter2D(src=img, ddepth=-1, kernel=sharp_kernel)\n",
    "        cv2.imwrite(pathname, flt_img)\n",
    "    elif data.project.values[index] == \"KIRC\":\n",
    "        path = path + \"KIRC/\"\n",
    "        pathname = path + name\n",
    "        cv2.imwrite(pathname, final_output[index])\n",
    "        img = cv2.imread(pathname)\n",
    "        flt_img = cv2.filter2D(src=img, ddepth=-1, kernel=sharp_kernel)\n",
    "        cv2.imwrite(pathname, flt_img)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\user\\anaconda3\\lib\\site-packages (1.10.2)\n",
      "Requirement already satisfied: torchvision in c:\\users\\user\\anaconda3\\lib\\site-packages (0.11.3)\n",
      "Requirement already satisfied: fastai in c:\\users\\user\\anaconda3\\lib\\site-packages (2.5.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.10.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision) (1.20.3)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: fastdownload<2,>=0.0.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastai) (0.0.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastai) (0.24.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastai) (1.3.4)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastai) (2.26.0)\n",
      "Requirement already satisfied: fastcore<1.4,>=1.3.22 in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastai) (1.3.29)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastai) (1.7.1)\n",
      "Requirement already satisfied: pip in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastai) (21.2.4)\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastai) (1.0.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastai) (3.4.3)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastai) (6.0)\n",
      "Requirement already satisfied: spacy<4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastai) (3.2.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastai) (21.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (2.4.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (0.4.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (2.0.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (2.11.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (1.0.6)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (8.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (2.0.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (1.8.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (0.6.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (1.0.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (3.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (58.0.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (3.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (4.62.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (3.0.9)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (0.7.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from packaging->fastai) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<4->fastai) (5.2.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->fastai) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->fastai) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->fastai) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->fastai) (2021.10.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<4->fastai) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<4->fastai) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->spacy<4->fastai) (1.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->fastai) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->fastai) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->fastai) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->fastai) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas->fastai) (2021.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn->fastai) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn->fastai) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision fastai\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/fastai/fastai.git 'C:\\Users\\user\\AppData\\Local\\Temp\\pip-req-build-hskw5smq'\n",
      "  ERROR: Error [WinError 2] The system cannot find the file specified while executing command git clone -q https://github.com/fastai/fastai.git 'C:\\Users\\user\\AppData\\Local\\Temp\\pip-req-build-hskw5smq'\n",
      "ERROR: Cannot find command 'git' - do you have 'git' installed and in your PATH?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/fastai/fastai.git\n",
      "  Cloning https://github.com/fastai/fastai.git to c:\\users\\user\\appdata\\local\\temp\\pip-req-build-hskw5smq\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n"
     ]
    }
   ],
   "source": [
    "# Note: Training each of the images\n",
    "!pip3 install git+https://github.com/fastai/fastai.git\n",
    "from fastai.vision import *\n",
    "from fastai.vision.data import ImageDataLoaders\n",
    "from fastai.metrics import accuracy\n",
    "from fastai.vision.all import *\n",
    "\n",
    "path = \"./data/train3/\"\n",
    "size = 224\n",
    "bs = 64\n",
    "# data = ImageDataBunch.from_folder(path, ds_tfms=get_transforms(do_flip=True, flip_vert=True),\n",
    "#                                   valid_pct=0.2, size=size, bs=bs)\n",
    "data = ImageDataLoaders.from_folder(path, valid_pct=0.2)\n",
    "learner = cnn_learner(data, models.resnet34, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.738169</td>\n",
       "      <td>2.172410</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>08:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.565060</td>\n",
       "      <td>1.084355</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>08:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.318954</td>\n",
       "      <td>0.938931</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>07:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.050849</td>\n",
       "      <td>0.767906</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>07:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.856424</td>\n",
       "      <td>0.694140</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>07:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.697350</td>\n",
       "      <td>0.586992</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>08:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.574687</td>\n",
       "      <td>0.510134</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>07:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.478485</td>\n",
       "      <td>0.366484</td>\n",
       "      <td>0.858333</td>\n",
       "      <td>07:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.398580</td>\n",
       "      <td>0.329389</td>\n",
       "      <td>0.858333</td>\n",
       "      <td>08:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.341422</td>\n",
       "      <td>0.313079</td>\n",
       "      <td>0.891667</td>\n",
       "      <td>08:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.292026</td>\n",
       "      <td>0.298610</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>07:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.247954</td>\n",
       "      <td>0.295945</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>08:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.216312</td>\n",
       "      <td>0.284871</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>08:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.188359</td>\n",
       "      <td>0.266717</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>07:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.163547</td>\n",
       "      <td>0.263793</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>08:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.142620</td>\n",
       "      <td>0.260193</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>07:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.126942</td>\n",
       "      <td>0.258273</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>07:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.111425</td>\n",
       "      <td>0.259767</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>07:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.097979</td>\n",
       "      <td>0.260251</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>08:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.087688</td>\n",
       "      <td>0.260994</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>08:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit_one_cycle(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to follow from here:\n",
    "1. Compare datasets with <= 9 features and datasets with > 9 features with other machine learning and deep learning methods\n",
    "2. Compare datasets with <= 25 features and datasets with > 25 features with other deep learning methods\n",
    "3. Follow step 1 and 2 with 5 different black and white images and colorful images.\n",
    "4. Compare different values with different resnets (14, 34, 52 etc). Comprehensive review of the efficiency of this method.\n",
    "5. Fine tuning to increase its efficiency where it is found to be efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\user\\anaconda3\\lib\\site-packages (4.5.5.62)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from opencv-python) (1.20.3)\n",
      "Requirement already satisfied: torch in c:\\users\\user\\anaconda3\\lib\\site-packages (1.10.2)\n",
      "Requirement already satisfied: torchvision in c:\\users\\user\\anaconda3\\lib\\site-packages (0.11.3)\n",
      "Requirement already satisfied: fastai in c:\\users\\user\\anaconda3\\lib\\site-packages (2.5.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.10.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision) (1.20.3)\n",
      "Requirement already satisfied: pip in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastai) (21.2.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastai) (21.0)\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastai) (1.0.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastai) (3.4.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastai) (0.24.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastai) (1.3.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastai) (1.7.1)\n",
      "Requirement already satisfied: spacy<4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastai) (3.2.2)\n",
      "Requirement already satisfied: fastcore<1.4,>=1.3.22 in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastai) (1.3.29)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastai) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastai) (2.26.0)\n",
      "Requirement already satisfied: fastdownload<2,>=0.0.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastai) (0.0.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (0.6.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (2.4.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (2.0.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (0.7.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (4.62.3)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (0.4.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (1.0.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (2.11.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (2.0.6)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (1.0.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (8.0.13)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (3.0.9)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (0.9.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (3.0.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (58.0.4)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (3.3.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (1.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from packaging->fastai) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<4->fastai) (5.2.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->fastai) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->fastai) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->fastai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->fastai) (3.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<4->fastai) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<4->fastai) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->spacy<4->fastai) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->fastai) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->fastai) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->fastai) (1.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->fastai) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas->fastai) (2021.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn->fastai) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn->fastai) (1.1.0)\n",
      "Collecting git+https://github.com/fastai/fastai.git\n",
      "  Cloning https://github.com/fastai/fastai.git to c:\\users\\user\\appdata\\local\\temp\\pip-req-build-lt7u1e4n\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/fastai/fastai.git 'C:\\Users\\user\\AppData\\Local\\Temp\\pip-req-build-lt7u1e4n'\n",
      "  ERROR: Error [WinError 2] The system cannot find the file specified while executing command git clone -q https://github.com/fastai/fastai.git 'C:\\Users\\user\\AppData\\Local\\Temp\\pip-req-build-lt7u1e4n'\n",
      "ERROR: Cannot find command 'git' - do you have 'git' installed and in your PATH?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.160908</td>\n",
       "      <td>2.050932</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>08:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.828643</td>\n",
       "      <td>1.542116</td>\n",
       "      <td>0.308333</td>\n",
       "      <td>07:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.554986</td>\n",
       "      <td>1.187348</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>07:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.290036</td>\n",
       "      <td>1.087588</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>08:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.044866</td>\n",
       "      <td>1.019526</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>08:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.858581</td>\n",
       "      <td>0.858614</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>07:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.712576</td>\n",
       "      <td>0.617340</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>07:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.601109</td>\n",
       "      <td>0.551188</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>07:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.509145</td>\n",
       "      <td>0.424248</td>\n",
       "      <td>0.841667</td>\n",
       "      <td>07:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.430308</td>\n",
       "      <td>0.437316</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>07:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.367753</td>\n",
       "      <td>0.444882</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>07:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.317565</td>\n",
       "      <td>0.459190</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>07:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.275430</td>\n",
       "      <td>0.464060</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>07:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.240882</td>\n",
       "      <td>0.467749</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>07:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.209965</td>\n",
       "      <td>0.459840</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>08:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.183438</td>\n",
       "      <td>0.456091</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>08:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.161927</td>\n",
       "      <td>0.450715</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>08:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.145412</td>\n",
       "      <td>0.444353</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>07:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.129972</td>\n",
       "      <td>0.450517</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>08:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.116695</td>\n",
       "      <td>0.445620</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>08:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data = pd.read_csv('cirrhosis.CSV')\n",
    "# Note: Importing the same dataset that we used before\n",
    "data_file = r\"./ML Research CNN/tcga.rnaseq_fpkm_uq.example.txt.gz\"\n",
    "data = pd.read_csv(data_file, sep=\"\\t\")\n",
    "df = data.loc[:, data.columns != 'project']\n",
    "from sklearn import preprocessing\n",
    "names = df.columns\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaled_df = scaler.fit_transform(df)\n",
    "scaled_df = pd.DataFrame(scaled_df, columns=names)\n",
    "pca = decomposition.PCA()\n",
    "df_plot = pd.DataFrame(pca.fit_transform(scaled_df), index=data.index)\n",
    "df_plot\n",
    "pca = decomposition.PCA()\n",
    "# fit : Run PCA\n",
    "df_PC = pca.fit(scaled_df)\n",
    "# Creating the 7*7 convolutional matrix from the 25 principal components\n",
    "def create_one_row(row):\n",
    "    list_temp = []\n",
    "    for value in row:\n",
    "        list_temp.append(value - row.mean())\n",
    "    list_row = np.array(list_temp).reshape(7, 7)\n",
    "    return list_row\n",
    "\n",
    "def transform_dataframe(df):\n",
    "    final_df = []\n",
    "    for i in range(len(df)):\n",
    "        final_df.append(create_one_row(df.iloc[i].values))\n",
    "    return final_df\n",
    "\n",
    "X = pd.DataFrame()\n",
    "for i in range(49):\n",
    "    X[i] = df_plot[i]\n",
    "final_df = transform_dataframe(X)\n",
    "trial = final_df[0]\n",
    "trial\n",
    "# Note: Importing the base image\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "img = Image.open('rose.jpg').convert('RGBA')\n",
    "arr = np.array(img)\n",
    "# Converting the base image into matrix in black and white form\n",
    "!pip3 install opencv-python\n",
    "import cv2\n",
    "image = cv2.imread(\"rose.jpg\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray\n",
    "from skimage.exposure import rescale_intensity\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "        \n",
    "# Note: Convolving with each of the 600 7*7 convolutional matrix     \n",
    "final_output = []\n",
    "for i in range(len(final_df)):\n",
    "    convolveOutput = cv2.filter2D(gray, -1, final_df[i])\n",
    "    final_output.append(convolveOutput)\n",
    "\n",
    "    \n",
    "    \n",
    "# Note: Storing the convolved base image in different folders based on the output\n",
    "emboss_kernel = np.array([[-1, 0, 0],\n",
    "                    [0, 0, 0],\n",
    "                    [0, 0, 1]])\n",
    "counter = 0\n",
    "for index in range(len(final_df)):\n",
    "    name = 'img' + str(counter) + '.png'\n",
    "    path = './data/train4/'\n",
    "    if data.project.values[index] == \"BRCA\":\n",
    "        path = path + \"BRCA/\"\n",
    "        pathname = path + name\n",
    "        cv2.imwrite(pathname, final_output[index])\n",
    "        img = cv2.imread(pathname)\n",
    "        flt_img = cv2.filter2D(src=img, ddepth=-1, kernel=emboss_kernel)\n",
    "        cv2.imwrite(pathname, flt_img)\n",
    "    elif data.project.values[index] == \"COAD\":\n",
    "        path = path + \"COAD/\"\n",
    "        pathname = path + name\n",
    "        cv2.imwrite(pathname, final_output[index])\n",
    "        img = cv2.imread(pathname)\n",
    "        flt_img = cv2.filter2D(src=img, ddepth=-1, kernel=emboss_kernel)\n",
    "        cv2.imwrite(pathname, flt_img)\n",
    "    elif data.project.values[index] == \"KIRC\":\n",
    "        path = path + \"KIRC/\"\n",
    "        pathname = path + name\n",
    "        cv2.imwrite(pathname, final_output[index])\n",
    "        img = cv2.imread(pathname)\n",
    "        flt_img = cv2.filter2D(src=img, ddepth=-1, kernel=emboss_kernel)\n",
    "        cv2.imwrite(pathname, flt_img)\n",
    "    counter = counter + 1\n",
    "!pip install torch torchvision fastai\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import accuracy\n",
    "\n",
    "# Note: Training each of the images\n",
    "!pip3 install git+https://github.com/fastai/fastai.git\n",
    "from fastai.vision import *\n",
    "from fastai.vision.data import ImageDataLoaders\n",
    "from fastai.metrics import accuracy\n",
    "from fastai.vision.all import *\n",
    "\n",
    "path = \"./data/train4/\"\n",
    "size = 224\n",
    "bs = 64\n",
    "# data = ImageDataBunch.from_folder(path, ds_tfms=get_transforms(do_flip=True, flip_vert=True),\n",
    "#                                   valid_pct=0.2, size=size, bs=bs)\n",
    "data = ImageDataLoaders.from_folder(path, valid_pct=0.2)\n",
    "learner = cnn_learner(data, models.resnet34, metrics=[accuracy])\n",
    "learner.fit_one_cycle(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
